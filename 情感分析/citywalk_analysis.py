"""
ä¸Šæµ·CityWalkæ‰“å¡ç‚¹æƒ…æ„Ÿåˆ†æç³»ç»Ÿ (æ— å¤–éƒ¨ä¾èµ–ç‰ˆæœ¬)
åŠŸèƒ½ï¼šæå–æ‰“å¡ç‚¹ -> æƒ…æ„Ÿåˆ†æ -> ç»¼åˆè¯„åˆ†
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import re
from collections import defaultdict
import warnings
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


class SimpleSentimentAnalyzer:
    """ç®€å•çš„ä¸­æ–‡æƒ…æ„Ÿåˆ†æå™¨ - åŸºäºå…³é”®è¯"""
    
    def __init__(self):
        # ç§¯æè¯æ±‡
        self.positive_words = {
            'å¾ˆæ£’': 0.9, 'å¾ˆå¥½': 0.85, 'å¾ˆç¾': 0.85, 'å¾ˆæ¼‚äº®': 0.9, 'ä¸é”™': 0.8,
            'å€¼å¾—': 0.85, 'æ¨è': 0.9, 'å–œæ¬¢': 0.85, 'æ»¡æ„': 0.8, 'å¼€å¿ƒ': 0.85,
            'èˆ’æœ': 0.8, 'ä¼˜é›…': 0.85, 'ç‰¹è‰²': 0.75, 'æœ‰è¶£': 0.85, 'å®Œç¾': 0.95,
            'ç²¾å¦™': 0.85, 'ç²¾è‡´': 0.8, 'äº®ç‚¹': 0.75, 'äº®ä¸½': 0.8, 'ç”Ÿæœº': 0.8,
            'å£®è§‚': 0.8, 'é›„ä¼Ÿ': 0.85, 'å¤æœ´': 0.75, 'æ°”æ¯': 0.7, 'æµ“åš': 0.7,
            'ç‹¬ç‰¹': 0.75, 'åˆ›æ„': 0.8, 'è‰ºæœ¯': 0.75, 'æ–‡åŒ–': 0.7, 'å†å²': 0.7,
            'å®‰é™': 0.75, 'æ¸…å¹½': 0.8, 'å®é™': 0.8, 'ç¥¥å’Œ': 0.85, 'æµªæ¼«': 0.85,
            'ç¹å': 0.7, 'çƒ­é—¹': 0.7, 'æ´»åŠ›': 0.75, 'æ¬¢ä¹': 0.85, 'æœ‰æ„æ€': 0.8,
            'äº²è¿‘': 0.75, 'åº•è•´': 0.7, 'å“å‘³': 0.75, 'è¿·äºº': 0.85, 'æ¢¦å¹»': 0.85,
            'é«˜çº§': 0.75, 'è®¾è®¡æ„Ÿ': 0.8, 'éŸµå‘³': 0.8, 'é£æƒ…': 0.75, 'æ°”è´¨': 0.75,
            'ç´ è´¨': 0.7, 'ä¿®å…»': 0.7, 'ä¼˜è´¨': 0.8, 'é¡¶çº§': 0.85
        }
        
        # å¦å®šè¯æ±‡
        self.negative_words = {
            'å¾ˆå·®': 0.15, 'ä¸å¥½': 0.2, 'å¾ˆä¸‘': 0.1, 'è®¨åŒ': 0.05, 'å¤±æœ›': 0.25,
            'åæ‚”': 0.15, 'æµªè´¹': 0.2, 'ä¸æ»¡': 0.25, 'éš¾è¿‡': 0.2, 'ä¼¤å¿ƒ': 0.15,
            'ç”Ÿæ°”': 0.2, 'ä¸èˆ’æœ': 0.25, 'æ‹¥æŒ¤': 0.3, 'æ’é˜Ÿ': 0.35, 'è´¹é’±': 0.3,
            'å¤ªé«˜': 0.35, 'è¿‡åº¦': 0.3, 'è´µ': 0.35, 'æ˜‚è´µ': 0.3, 'å‘': 0.15,
            'éª—': 0.1, 'ç¼ºå°‘': 0.35, 'æ²¡æœ‰': 0.4, 'æ— ': 0.4, 'æ²¡': 0.4,
            'å†·æ¸…': 0.35, 'è’å‡‰': 0.25, 'ç ´æ—§': 0.2, 'é™ˆæ—§': 0.35, 'è½å': 0.3,
            'ä¸æ–¹ä¾¿': 0.3, 'ä¸èˆ’é€‚': 0.3, 'éš¾å—': 0.25, 'ç´¯': 0.3, 'ç–²æƒ«': 0.3,
            'åæ„Ÿ': 0.15, 'åŒçƒ¦': 0.2, 'çƒ¦': 0.25, 'è®¨åŒ': 0.15, 'åŒ': 0.25,
            'ä¸': 0.4, 'æ²¡': 0.4, 'æ²¡æœ‰': 0.4, 'æ— ': 0.4, 'åˆ«': 0.35
        }
        
        # å¦å®šä¿®é¥°è¯
        self.negation_words = {'ä¸', 'æ²¡', 'æ— ', 'åˆ«', 'è«'}
    
    def analyze(self, text):
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿå¾—åˆ† (0-1)"""
        if not text or not isinstance(text, str):
            return 0.5
        
        text = text.lower()
        words = re.findall(r'[\u4e00-\u9fa5]+|[a-zA-Z]+', text)
        
        positive_score = 0
        negative_score = 0
        
        for i, word in enumerate(words):
            # æ£€æŸ¥ç§¯æè¯æ±‡
            if word in self.positive_words:
                score = self.positive_words[word]
                # æ£€æŸ¥æ˜¯å¦è¢«å¦å®š
                if i > 0 and words[i-1] in self.negation_words:
                    negative_score += score
                else:
                    positive_score += score
            
            # æ£€æŸ¥å¦å®šè¯æ±‡
            elif word in self.negative_words:
                score = self.negative_words[word]
                negative_score += score
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        total = positive_score + negative_score
        if total == 0:
            return 0.5
        
        sentiment = positive_score / total
        return min(1.0, max(0.0, sentiment))


def preprocess_text(text):
    """æ–‡æœ¬é¢„å¤„ç†"""
    if not isinstance(text, str):
        return ""
    text = re.sub(r'http[s]?://\S+', '', text)
    text = re.sub(r'[^\w\u4e00-\u9fa5]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def load_data():
    """åŠ è½½æ•°æ®"""
    print("=" * 70)
    print("ğŸŒ† ä¸Šæµ·CityWalkæ‰“å¡ç‚¹æƒ…æ„Ÿåˆ†æç³»ç»Ÿ".center(70))
    print("=" * 70)
    
    possible_paths = [
        'å»é‡åçš„æ•°æ®.csv',
        'å»é‡åçš„æ•°æ®.xlsx',
        os.path.expanduser('~/Desktop/å»é‡åçš„æ•°æ®.xlsx'),
        os.path.expanduser('~/Desktop/åŸæ•°æ®.xlsx'),
    ]
    
    df = None
    for path in possible_paths:
        try:
            if path.endswith('.xlsx'):
                df = pd.read_excel(path)
            elif path.endswith('.csv'):
                df = pd.read_csv(path, encoding='utf-8')
            
            if df is not None and len(df) > 0:
                print(f"\nâœ… æˆåŠŸåŠ è½½æ•°æ®: {path}")
                return df
        except:
            continue
    
    print("\nâš ï¸  æœªæ‰¾åˆ°å®é™…æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®æ¼”ç¤º")
    return create_sample_data()


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    sample_data = {
        'content': [
            'æ­¦åº·è·¯ä¸Šçš„è€æ´‹æˆ¿å……æ»¡å†å²æ°”æ¯ï¼Œæ•£æ­¥å¾ˆèˆ’æœï¼Œå€¼å¾—ä¸€æ¥',
            'æ–°å¤©åœ°çš„å»ºç­‘å¾ˆæœ‰è®¾è®¡æ„Ÿï¼Œä½†æ¶ˆè´¹å¤ªé«˜ï¼Œæœ‰ç‚¹å¤±æœ›',
            'è±«å›­æ˜¯ä¸Šæµ·çš„æ ‡å¿—æ€§æ™¯ç‚¹ï¼Œå›­æ—è®¾è®¡ç²¾å¦™ï¼Œå¾ˆå€¼å¾—çœ‹',
            'å¤–æ»©çœ‹æµ¦æ±Ÿå¤œæ™¯å¾ˆç¾ï¼Œä½†äººå¤ªå¤šäº†ï¼Œæ‹ç…§ä¸æ–¹ä¾¿',
            'ç”°å­åŠæœ‰å¾ˆå¤šç‰¹è‰²å°åº—ï¼Œåˆ›æ„åè¶³ï¼Œé€›äº†åŠå¤©è¿˜æ²¡é€›å¤Ÿ',
            'åŸéšåº™çš„ä¼ ç»Ÿå»ºç­‘ä¿æŠ¤å¾—å¾ˆå¥½ï¼Œæ„Ÿå—åˆ°äº†è€ä¸Šæµ·çš„æ–‡åŒ–',
            'é™†å®¶å˜´çš„é«˜æ¥¼å¾ˆå£®è§‚ï¼Œä½†ç¼ºå°‘äººæ–‡æ°”æ¯',
            'å®‰ç¦è·¯å¾ˆå®‰é™ï¼Œå¤æ ‘å¾ˆå¤šï¼Œç‰¹åˆ«é€‚åˆæ•£æ­¥',
            'æ€å—å…¬é¦†çš„ç¯å¢ƒå¾ˆä¼˜é›…ï¼Œé€‚åˆæ‹ç…§',
            'é™å®‰å¯ºå¾ˆå®é™ç¥¥å’Œï¼Œè™½ç„¶äººå¤šä½†å¾ˆæœ‰æ°›å›´',
            'æœ±å®¶è§’çš„å¤é•‡é£æƒ…å¾ˆæµ“åšï¼Œæ°´ä¹¡æ™¯è‰²å¾ˆç¾',
            'ä¸Šç”Ÿæ–°æ‰€çš„è€å»ºç­‘æ–°ç©æ³•å¾ˆæœ‰æ„æ€ï¼Œå¾ˆæœ‰è¶£',
            'æ„šå›­è·¯çš„ç”Ÿæ´»æ°”æ¯å¾ˆæµ“ï¼Œæ„Ÿè§‰å¾ˆäº²è¿‘',
            'å¤šä¼¦è·¯çš„æ–‡åŒ–åº•è•´å¾ˆæ·±ï¼Œå€¼å¾—ç»†ç»†å“å‘³',
            'æ­¦åº·è·¯å’Œç”°å­åŠéƒ½å¾ˆæ¨èï¼Œå„æœ‰ç‰¹è‰²',
            'å¤–æ»©çš„æ™¯è‰²ä¸€èˆ¬ï¼Œæ„Ÿè§‰æ²¡æƒ³è±¡ä¸­é‚£ä¹ˆå¥½',
            'è¿ªå£«å°¼ä¹å›­å¾ˆæ¬¢ä¹ï¼Œå°æœ‹å‹å¾ˆå¼€å¿ƒï¼Œä½†æ’é˜Ÿå¤ªä¹…',
            'æ«æ³¾å¤é•‡æ¯”è¾ƒå†·æ¸…ï¼Œä½†å¤è‰²å¤é¦™ï¼Œæœ‰å†å²æ„Ÿ',
            'ä¸ƒå®æœ‰æ±Ÿå—æ°´ä¹¡çš„éŸµå‘³ï¼Œå¾ˆä¸é”™',
            'æ·®æµ·è·¯æ˜¯è´­ç‰©å¤©å ‚ï¼Œå¾ˆç¹å',
            'å¾å®¶æ±‡å¤©ä¸»æ•™å ‚åº„ä¸¥è‚ƒç©†ï¼Œå»ºç­‘å¾ˆæœ‰ç‰¹è‰²',
            'é¾™åå¯ºçš„å†å²æ‚ ä¹…ï¼Œç¯å¢ƒå¾ˆæ¸…å¹½',
            '1933è€åœºåŠæ”¹é€ å¾—å¾ˆç‰¹åˆ«ï¼Œæœ‰è‰ºæœ¯æ°”æ¯',
            'ç”œçˆ±è·¯å¾ˆæµªæ¼«ï¼Œé€‚åˆæƒ…ä¾£æ‰“å¡',
            'M50åˆ›æ„å›­åŒºå¾ˆæœ‰è‰ºæœ¯èŒƒå„¿',
        ]
    }
    return pd.DataFrame(sample_data)


def main():
    """ä¸»å‡½æ•°"""
    
    # 1. åŠ è½½æ•°æ®
    df = load_data()
    
    if 'content' not in df.columns:
        cols = [c for c in df.columns if 'å†…å®¹' in c or 'è¯„è®º' in c or 'æ–‡æœ¬' in c]
        if cols:
            df.rename(columns={cols[0]: 'content'}, inplace=True)
        else:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°å†…å®¹åˆ—\nå¯ç”¨å­—æ®µ: {df.columns.tolist()}")
            return
    
    print(f"ğŸ“Š æ•°æ®é‡: {len(df)} æ¡è¯„è®º\n")
    
    # 2. æ–‡æœ¬é¢„å¤„ç†
    print("ğŸ”„ æ­£åœ¨é¢„å¤„ç†æ–‡æœ¬...")
    df['processed'] = df['content'].apply(preprocess_text)
    valid_count = len(df[df['processed'] != ''])
    print(f"âœ“ æœ‰æ•ˆæ–‡æœ¬: {valid_count}/{len(df)} ({100*valid_count/len(df):.1f}%)\n")
    
    # 3. æ‰“å¡ç‚¹åº“
    landmarks = [
        'å¤–æ»©', 'å—äº¬è·¯', 'è±«å›­', 'åŸéšåº™', 'ç”°å­åŠ', 'æ–°å¤©åœ°',
        'æ­¦åº·è·¯', 'å®‰ç¦è·¯', 'æ€å—å…¬é¦†', 'é™å®‰å¯º', 'é™†å®¶å˜´',
        'è¿ªå£«å°¼', 'æœ±å®¶è§’', 'æ«æ³¾', 'ä¸ƒå®', 'M50', '1933',
        'ä¸Šç”Ÿæ–°æ‰€', 'æ„šå›­è·¯', 'æ·®æµ·è·¯', 'ç”œçˆ±è·¯', 'å¤šä¼¦è·¯',
        'å¾å®¶æ±‡', 'é¾™åå¯º', 'å…±é’æ£®æ—å…¬å›­', 'ä¸œå¹³å›½å®¶æ£®æ—å…¬å›­'
    ]
    
    # 4. æå–æ‰“å¡ç‚¹
    print("ğŸ” æ­£åœ¨æå–æ‰“å¡ç‚¹...")
    landmark_data = defaultdict(list)
    landmark_raw = defaultdict(list)
    
    for idx, row in df.iterrows():
        processed = row['processed']
        original = row['content']
        for landmark in landmarks:
            if landmark in processed:
                landmark_data[landmark].append(processed)
                landmark_raw[landmark].append(original)
    
    if not landmark_data:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ‰“å¡ç‚¹")
        return
    
    # æŒ‰æ•°é‡æ’åº
    sorted_landmarks = sorted(landmark_data.items(), key=lambda x: len(x[1]), reverse=True)
    
    print(f"\nâœ“ è¯†åˆ«åˆ° {len(sorted_landmarks)} ä¸ªæ‰“å¡ç‚¹:")
    for i, (lm, comments) in enumerate(sorted_landmarks[:10], 1):
        print(f"   {i:2d}. {lm:10s} ({len(comments):3d} æ¡è¯„è®º)")
    if len(sorted_landmarks) > 10:
        print(f"   ... ç­‰å…± {len(sorted_landmarks)} ä¸ª")
    
    # 5. æƒ…æ„Ÿåˆ†æ
    print("\n" + "=" * 70)
    print("ğŸš€ æ‰§è¡Œæƒ…æ„Ÿåˆ†æ...".center(70))
    print("=" * 70 + "\n")
    
    analyzer = SimpleSentimentAnalyzer()
    results = []
    
    for idx, (landmark, comments) in enumerate(sorted_landmarks, 1):
        print(f"[{idx}/{len(sorted_landmarks)}] åˆ†æ {landmark:12s}", end=" ", flush=True)
        
        # åˆ†ææ¯æ¡è¯„è®º
        sentiments = [analyzer.analyze(c) for c in comments]
        
        # ç»Ÿè®¡æŒ‡æ ‡
        avg_sentiment = np.mean(sentiments)
        positive_count = sum(1 for s in sentiments if s > 0.6)
        negative_count = sum(1 for s in sentiments if s < 0.4)
        positive_rate = positive_count / len(sentiments) if sentiments else 0
        
        # æ‰¾æœ€å…·ä»£è¡¨æ€§çš„è¯„è®º
        best_idx = np.argmax(sentiments)
        sample_text = landmark_raw[landmark][best_idx][:45]
        
        # æƒ…æ„Ÿç­‰çº§
        if avg_sentiment >= 0.7:
            grade = 'å¼ºæ­£é¢'
        elif avg_sentiment >= 0.6:
            grade = 'æ­£é¢'
        elif avg_sentiment >= 0.4:
            grade = 'ä¸­ç«‹'
        else:
            grade = 'è´Ÿé¢'
        
        results.append({
            'æ‰“å¡ç‚¹': landmark,
            'æƒ…æ„Ÿå¾—åˆ†': round(avg_sentiment, 4),
            'æƒ…æ„Ÿç­‰çº§': grade,
            'ç§¯æè¯„è®ºæ•°': positive_count,
            'è´Ÿé¢è¯„è®ºæ•°': negative_count,
            'ç§¯æç‡': round(positive_rate, 3),
            'æ ·æœ¬é‡': len(comments),
            'ç¤ºä¾‹': sample_text
        })
        
        # è¿›åº¦æ¡
        print(f"âœ“ {avg_sentiment:.3f}")
    
    # åˆ›å»ºç»“æœDataFrame
    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values('æƒ…æ„Ÿå¾—åˆ†', ascending=False)
    
    # 6. ä¿å­˜ç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ’¾ ä¿å­˜ç»“æœ".center(70))
    print("=" * 70 + "\n")
    
    csv_path = 'æ‰“å¡ç‚¹æƒ…æ„Ÿåˆ†æç»“æœ.csv'
    results_df.to_csv(csv_path, index=False, encoding='utf_8_sig')
    print(f"âœ… CSV æ–‡ä»¶: {csv_path}")
    
    # 7. æ˜¾ç¤ºè¡¨æ ¼ç»“æœ
    print("\nğŸ“‹ æƒ…æ„Ÿåˆ†æç»“æœæ±‡æ€»ï¼š\n")
    print(f"{'æ’å':^4} | {'æ‰“å¡ç‚¹':^12} | {'å¾—åˆ†':^6} | {'ç­‰çº§':^6} | {'ç§¯æç‡':^7} | {'æ ·æœ¬':^5} | {'ç¤ºä¾‹':^20}")
    print("-" * 80)
    
    for i, (_, row) in enumerate(results_df.iterrows(), 1):
        print(f"{i:4d} | {row['æ‰“å¡ç‚¹']:12s} | {row['æƒ…æ„Ÿå¾—åˆ†']:6.3f} | {row['æƒ…æ„Ÿç­‰çº§']:6s} | {row['ç§¯æç‡']:6.1%} | {row['æ ·æœ¬é‡']:5d} | {row['ç¤ºä¾‹']:20s}")
    
    # 8. Top5æ¨è
    print("\n" + "=" * 70)
    print("ğŸ† æœ€å€¼å¾—æ¨èçš„TOP5æ‰“å¡ç‚¹".center(70))
    print("=" * 70 + "\n")
    
    top5 = results_df.head(5)
    for i, (_, row) in enumerate(top5.iterrows(), 1):
        stars = "â­" * int(row['æƒ…æ„Ÿå¾—åˆ†'] * 5)
        print(f"{i}. {row['æ‰“å¡ç‚¹']:12s} | å¾—åˆ†: {row['æƒ…æ„Ÿå¾—åˆ†']:.3f} {stars} | è¯„è®ºæ•°: {row['æ ·æœ¬é‡']}")
    
    # 9. å¯è§†åŒ–
    print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...", end=" ", flush=True)
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('ğŸŒ† ä¸Šæµ·CityWalkæ‰“å¡ç‚¹æƒ…æ„Ÿåˆ†ææŠ¥å‘Š', fontsize=18, fontweight='bold')
    
    # å›¾1ï¼šæƒ…æ„Ÿå¾—åˆ†æ’è¡Œ
    ax1 = axes[0, 0]
    cmap = plt.cm.get_cmap('RdYlGn')
    colors = [cmap(s) for s in results_df['æƒ…æ„Ÿå¾—åˆ†']]
    bars = ax1.barh(results_df['æ‰“å¡ç‚¹'], results_df['æƒ…æ„Ÿå¾—åˆ†'], color=colors, edgecolor='grey', linewidth=1.5)
    ax1.set_xlabel('æƒ…æ„Ÿå¾—åˆ†', fontsize=11)
    ax1.set_title('ğŸ“Š æƒ…æ„Ÿå¾—åˆ†æ’è¡Œ', fontsize=12, fontweight='bold')
    ax1.set_xlim(0.3, 1.0)
    ax1.grid(axis='x', linestyle='--', alpha=0.5)
    
    for bar, score in zip(bars, results_df['æƒ…æ„Ÿå¾—åˆ†']):
        ax1.text(score + 0.02, bar.get_y() + bar.get_height()/2, f'{score:.3f}', 
                va='center', fontsize=8)
    
    # å›¾2ï¼šæ ·æœ¬é‡å¯¹æ¯”
    ax2 = axes[0, 1]
    ax2.bar(range(len(results_df)), results_df['æ ·æœ¬é‡'], color='skyblue', edgecolor='navy', linewidth=1.5)
    ax2.set_xticks(range(len(results_df)))
    ax2.set_xticklabels(results_df['æ‰“å¡ç‚¹'], rotation=45, ha='right', fontsize=9)
    ax2.set_ylabel('è¯„è®ºæ•°é‡', fontsize=11)
    ax2.set_title('ğŸ“ˆ è¯„è®ºæ•°é‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    ax2.grid(axis='y', linestyle='--', alpha=0.5)
    
    # å›¾3ï¼šç§¯æç‡
    ax3 = axes[1, 0]
    ax3.bar(range(len(results_df)), results_df['ç§¯æç‡'], color='lightgreen', edgecolor='darkgreen', linewidth=1.5)
    ax3.set_xticks(range(len(results_df)))
    ax3.set_xticklabels(results_df['æ‰“å¡ç‚¹'], rotation=45, ha='right', fontsize=9)
    ax3.set_ylabel('ç§¯æè¯„è®ºæ¯”ä¾‹', fontsize=11)
    ax3.set_ylim(0, 1)
    ax3.set_title('ğŸ˜Š ç§¯æè¯„è®ºç‡', fontsize=12, fontweight='bold')
    ax3.grid(axis='y', linestyle='--', alpha=0.5)
    
    # å›¾4ï¼šç­‰çº§åˆ†å¸ƒé¥¼å›¾
    ax4 = axes[1, 1]
    grade_counts = results_df['æƒ…æ„Ÿç­‰çº§'].value_counts()
    colors_pie = ['#2ca02c', '#ffdd57', '#ff7f0e', '#d62728']
    grade_order = ['å¼ºæ­£é¢', 'æ­£é¢', 'ä¸­ç«‹', 'è´Ÿé¢']
    grade_counts = grade_counts.reindex([g for g in grade_order if g in grade_counts.index])
    ax4.pie(grade_counts.values, labels=grade_counts.index, autopct='%1.0f%%',
            colors=colors_pie[:len(grade_counts)], startangle=90)
    ax4.set_title('ğŸ¯ æƒ…æ„Ÿç­‰çº§åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    png_path = 'æ‰“å¡ç‚¹æƒ…æ„Ÿåˆ†æç»“æœ.png'
    plt.savefig(png_path, dpi=300, bbox_inches='tight')
    print(f"âœ“")
    print(f"âœ… PNG æ–‡ä»¶: {png_path}\n")
    
    # 10. æ·±åº¦æ´å¯Ÿ
    print("=" * 70)
    print("ğŸ’¡ æ·±åº¦æ´å¯Ÿåˆ†æ".center(70))
    print("=" * 70 + "\n")
    
    overall_score = results_df['æƒ…æ„Ÿå¾—åˆ†'].mean()
    overall_positive_rate = results_df['ç§¯æç‡'].mean()
    
    if overall_score >= 0.7:
        desc = "ğŸŒŸ é«˜åº¦æ¨è"
    elif overall_score >= 0.6:
        desc = "ğŸ˜Š å€¼å¾—ä½“éªŒ"
    elif overall_score >= 0.5:
        desc = "ğŸ˜ ä¸€èˆ¬"
    else:
        desc = "ğŸ˜ éœ€è°¨æ…"
    
    print(f"ğŸ“Š æ•´ä½“è¯„ä¼°:")
    print(f"   â€¢ ç»¼åˆæƒ…æ„Ÿå¾—åˆ†: {overall_score:.3f}/1.0 - {desc}")
    print(f"   â€¢ æ•´ä½“ç§¯æç‡: {overall_positive_rate:.1%}")
    print(f"   â€¢ åˆ†ææ‰“å¡ç‚¹: {len(results_df)} ä¸ª")
    print(f"   â€¢ æ€»è¯„è®ºæ•°: {results_df['æ ·æœ¬é‡'].sum()} æ¡")
    
    print(f"\nğŸ… æ’åæ¦‚è§ˆ:")
    print(f"   â€¢ ğŸ¥‡ æœ€ä½³: {results_df.iloc[0]['æ‰“å¡ç‚¹']} ({results_df.iloc[0]['æƒ…æ„Ÿå¾—åˆ†']:.3f})")
    if len(results_df) > 1:
        most_comments = results_df.nlargest(1, 'æ ·æœ¬é‡').iloc[0]
        print(f"   â€¢ ğŸ”¥ çƒ­é—¨: {most_comments['æ‰“å¡ç‚¹']} ({most_comments['æ ·æœ¬é‡']} æ¡è¯„è®º)")
        print(f"   â€¢ âŒ éœ€æ”¹: {results_df.iloc[-1]['æ‰“å¡ç‚¹']} ({results_df.iloc[-1]['æƒ…æ„Ÿå¾—åˆ†']:.3f})")
    
    print(f"\nğŸ“ˆ æŒ‰ç­‰çº§ç»Ÿè®¡:")
    for grade in ['å¼ºæ­£é¢', 'æ­£é¢', 'ä¸­ç«‹', 'è´Ÿé¢']:
        items = results_df[results_df['æƒ…æ„Ÿç­‰çº§'] == grade]
        if len(items) > 0:
            names = items['æ‰“å¡ç‚¹'].tolist()
            print(f"   â€¢ {grade:6s}: {', '.join(names[:5])}", end="")
            if len(names) > 5:
                print(f" ç­‰ ({len(names)} ä¸ª)")
            else:
                print()
    
    print("\n" + "=" * 70)
    print("âœ¨ åˆ†æå®Œæˆï¼".center(70))
    print("=" * 70)
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   1. è¯¦ç»†ç»“æœ: {csv_path}")
    print(f"   2. å¯è§†åŒ–: {png_path}")
    print(f"\n" + "=" * 70 + "\n")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    input("\næŒ‰å›è½¦é”®å…³é—­ç¨‹åº...")
